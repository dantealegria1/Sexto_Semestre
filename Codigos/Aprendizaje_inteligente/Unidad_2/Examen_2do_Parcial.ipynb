{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos las librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creamos nuestras variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global PROHIBIDAS\n",
    "PROHIBIDAS = [\"\"]\n",
    "global ARCHIVO\n",
    "ARCHIVO = \"comments.csv\"\n",
    "global DATASET\n",
    "DATASET = pd.read_csv(ARCHIVO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para obtener los indices de las reviews positivas y negativas\n",
    "def Probabilidades_Iniciales(dataset):\n",
    "    Numero_Reviews_Positivas = 0\n",
    "    Numero_Reviews_Negativas = 0\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset[\"comment\"].iloc[i] != \"\":\n",
    "            if dataset[\"rating\"].iloc[i] == 1:\n",
    "                Numero_Reviews_Positivas += 1\n",
    "            if dataset[\"rating\"].iloc[i] == 0:\n",
    "                Numero_Reviews_Negativas += 1\n",
    "    Probabilaidad_Negativa = Numero_Reviews_Negativas/len(dataset)\n",
    "    Probabilidad_Positiva = Numero_Reviews_Positivas/len(dataset)\n",
    "    return Probabilaidad_Negativa, Probabilidad_Positiva\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectores_Palabras(dataset):\n",
    "    Palabras_Positivas = []\n",
    "    Palabras_Negativas = []\n",
    "    Largo = len(dataset)\n",
    "    for i in range(Largo):\n",
    "        if dataset[\"comment\"].iloc[i] != \"\": \n",
    "            if dataset[\"rating\"].iloc[i] == 1 : \n",
    "                Palabras_Positivas.append(dataset[\"comment\"].iloc[i])\n",
    "            if dataset[\"rating\"].iloc[i] == 0: \n",
    "                Palabras_Negativas.append(dataset[\"comment\"].iloc[i])\n",
    "    return Palabras_Positivas, Palabras_Negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filtar_Palabras(Palabras):\n",
    "    Palabras_Filtradas = []\n",
    "    for review in Palabras:\n",
    "        if isinstance(review, str):  # Check if the element is a string\n",
    "            tokens = word_tokenize(review)\n",
    "            stopwords_ingles = set(stopwords.words('spanish'))\n",
    "            Palabras_Filtradas.extend([Palabra.lower() for Palabra in tokens\n",
    "                                        if Palabra.isalpha() and Palabra.lower()\n",
    "                                        not in stopwords_ingles and Palabra.lower() not in PROHIBIDAS])\n",
    "    return Palabras_Filtradas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Probabilidad_Palabra(Palabra, Review):\n",
    "    Probabilidad_Palabra = (Review.count(Palabra)+1) / len(Review)\n",
    "    return Probabilidad_Palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para obtener la frecuencia de las palabras en las reviews\n",
    "def Frecuencia_Palabras(Palabras):\n",
    "    Frecuencia = Counter(Palabras)\n",
    "    print(Frecuencia.most_common(10))\n",
    "    return Frecuencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes(Review, Palabras):\n",
    "    Probabilidad = 1\n",
    "    Probabilidades = []\n",
    "    # Ensure Review is a string\n",
    "    if not isinstance(Review, str):\n",
    "        Review = str(Review)\n",
    "    Review_Filtrada = Filtar_Palabras([Review])\n",
    "    Review_Token = word_tokenize(Review)\n",
    "    for Palabra in Review_Token:\n",
    "        if Palabra not in Palabras:\n",
    "            Probabilidad = Probabilidad * 1.\n",
    "        else:\n",
    "            Probabilidad = Probabilidad + Probabilidad_Palabra(Palabra, Palabras)\n",
    "    return Probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pruebas(Palabras_Positivas, Palabras_Negativas,Review_Prueba,dataset):\n",
    "    Probabilidad_Inicial_Negativa, Probabilidad_Inicial_Positiva = Probabilidades_Iniciales(dataset)\n",
    "    Probabilidad_De_Ser_Positiva = Naive_Bayes(Review_Prueba, Palabras_Positivas)\n",
    "    Probabilidad_De_Ser_Positiva *= Probabilidad_Inicial_Positiva\n",
    "    Probabilidad_De_Ser_Negativa = Naive_Bayes(Review_Prueba, Palabras_Negativas)\n",
    "    Probabilidad_De_Ser_Negativa *= Probabilidad_Inicial_Negativa\n",
    "    Resultado = 0\n",
    "    if Probabilidad_De_Ser_Positiva > Probabilidad_De_Ser_Negativa:\n",
    "        Resultado = 1\n",
    "    if Probabilidad_De_Ser_Positiva and Probabilidad_De_Ser_Negativa == 0:\n",
    "        Resultado = -1\n",
    "    if Resultado == 0:\n",
    "        print(Probabilidad_De_Ser_Negativa, Probabilidad_De_Ser_Positiva)\n",
    "    return Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Matriz_Confusion(dataset, Palabras_Positivas, Palabras_Negativas):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset[\"comment\"].iloc[i] != \"\":\n",
    "            if dataset[\"rating\"].iloc[i] == 1:\n",
    "                y_true.append(1)\n",
    "            if dataset[\"rating\"].iloc[i] == 0:\n",
    "                y_true.append(0)\n",
    "    for i in range(len(dataset)):\n",
    "        if Pruebas(Palabras_Positivas, Palabras_Negativas, dataset[\"comment\"].iloc[i],dataset) == 1:\n",
    "            y_pred.append(1)\n",
    "        if Pruebas(Palabras_Positivas, Palabras_Negativas, dataset[\"comment\"].iloc[i],dataset) == 0:\n",
    "            y_pred.append(0)\n",
    "            print(\"Comentario\")\n",
    "            print(dataset[\"comment\"].iloc[i] + \"\\n\")\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    Presicion = (tn+tp)/(tn+fp+fn+tp)\n",
    "    FalsosPositivos = fp/(tn+fp)\n",
    "    FalsosNegativos = fn/(fn+tp)\n",
    "    Error = 1-Presicion\n",
    "    AcertividadPositiva = tp/(fp+tp)\n",
    "    if tn + fn == 0:\n",
    "        AcertividadNegativa = 0 # or 1, depending on your preference\n",
    "    else:\n",
    "        AcertividadNegativa = tn / (tn + fn) \n",
    "    tabla = pd.DataFrame(data = [Presicion,Error,FalsosPositivos,FalsosNegativos,AcertividadPositiva,AcertividadNegativa], index = [\"Presicion\",\"Error\",\"Falsos Positivos\",\"Falsos Negativos\",\"Acertividad Positiva\",\"Acertividad Negativa\"], columns = [\"Valor\"])\n",
    "    print(tabla)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Dividir el conjunto de datos en entrenamiento y prueba (70% entrenamiento, 30% prueba)\n",
    "    df_train, df_test = train_test_split(DATASET, test_size=0.2, random_state=0)\n",
    "    #print(df_test.head(100))\n",
    "    #print(df_train.head(100))\n",
    "\n",
    "    # Obtener palabras de los conjuntos de entrenamiento y prueba\n",
    "    Palabras_Positivas_train, Palabras_Negativas_train = Vectores_Palabras(df_train)\n",
    "    #Palabras_Positivas_test, Palabras_Negativas_test = Vectores_Palabras(df_test)\n",
    "\n",
    "    # Filtrar palabras\n",
    "    Palabras_Positivas_train = Filtar_Palabras(Palabras_Positivas_train)\n",
    "    Palabras_Negativas_train = Filtar_Palabras(Palabras_Negativas_train)\n",
    "\n",
    "    #print('Cantidad de palabras positivas en el conjunto de entrenamiento:', len(Palabras_Positivas_train))\n",
    "    #print('Cantidad de palabras negativas en el conjunto de entrenamiento:', len(Palabras_Negativas_train))\n",
    "    #print('Cantidad de palabras positivas en el conjunto de prueba:', len(Palabras_Positivas_test))\n",
    "    #print('Cantidad de palabras negativas en el conjunto de prueba:', len(Palabras_Negativas_test))\n",
    "\n",
    "    #print(\"Frecuencia de las palabras positivas y negativas en el conjunto de entrenamiento :)\")\n",
    "    Frecuencia_Palabras(Palabras_Positivas_train)\n",
    "    Frecuencia_Palabras(Palabras_Negativas_train)\n",
    "    print()\n",
    "\n",
    "    Matriz_Confusion(df_test, Palabras_Positivas_train, Palabras_Negativas_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('excelente', 333), ('bien', 324), ('producto', 310), ('calidad', 272), ('buena', 247), ('precio', 234), ('buen', 220), ('si', 153), ('fácil', 144), ('recomiendo', 126)]\n",
      "[('calidad', 33), ('producto', 32), ('agua', 26), ('bien', 25), ('mala', 22), ('si', 22), ('solo', 21), ('malo', 18), ('plástico', 15), ('verdad', 13)]\n",
      "\n",
      "                         Valor\n",
      "Presicion             0.862745\n",
      "Error                 0.137255\n",
      "Falsos Positivos      1.000000\n",
      "Falsos Negativos      0.000000\n",
      "Acertividad Positiva  0.862745\n",
      "Acertividad Negativa  0.000000\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
